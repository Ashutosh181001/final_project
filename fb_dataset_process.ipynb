{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bb8ac6-1708-42da-9bc3-ae15629ebef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1275230-9624-471c-a7d3-74fcf613ed27",
   "metadata": {},
   "source": [
    "### Functions to Process Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5659578a-33ca-4fde-a2e5-9e7a50697c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON format in file: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bd8562-d87a-4981-8b99-532227c6eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_events_data(json_data, team_name_dict):\n",
    "    if json_data is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    parsed_data = [{\n",
    "        \"match_id\": entry.get(\"matchId\"),\n",
    "        \"match_period\": entry.get(\"matchPeriod\"),\n",
    "        \"event_sec\": entry.get(\"eventSec\"),\n",
    "        \"event_name\": entry.get(\"eventName\"),\n",
    "        \"player_id\": entry.get(\"playerId\"),\n",
    "        \"team_id\": entry.get(\"teamId\"),\n",
    "        \"team_caused_event\": team_name_dict.get(entry.get(\"teamId\"), \"Unknown\"),  # Look up the team name that caused the event\n",
    "        \"sub_event_name\": entry.get(\"subEventName\"),\n",
    "        \"positions\": entry.get(\"positions\", []),\n",
    "        \"tags\": [tag.get(\"id\") for tag in entry.get(\"tags\", [])]\n",
    "    } for entry in json_data if entry.get(\"tags\")]\n",
    "\n",
    "    df_events = pd.json_normalize(parsed_data, sep='_')\n",
    "    return df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e63dca-99e0-4cbb-baad-a32f456cb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_time_and_create_breaks(group):\n",
    "    halftime_end = group[group['match_period'] == '1H']['event_sec'].max()\n",
    "    break_events = [\n",
    "        {\n",
    "            'match_id': group.name,\n",
    "            'match_period': 'Break',\n",
    "            'event_sec': halftime_end + sec,\n",
    "            'event_name': 'Break Time',\n",
    "            'sub_event_name': 'Break Time',\n",
    "            'positions': [{'y': 0, 'x': 0}, {'y': 0, 'x': 0}],\n",
    "            'tags': ['Break Time']\n",
    "        }\n",
    "        for sec in range(3, 900 + 3, 3)\n",
    "    ]\n",
    "    \n",
    "    break_df = pd.DataFrame(break_events)\n",
    "    group = pd.concat([group, break_df], ignore_index=True)\n",
    "    group.loc[group['match_period'] == '2H', 'event_sec'] += halftime_end + 903\n",
    "    return group.sort_values(by='event_sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56425a77-e595-41a4-8e3a-72c482a9eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matches_data(json_data, team_name_dict):\n",
    "    if json_data is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Modified to include home_team_id and away_team_id\n",
    "    parsed_data = [{\n",
    "        \"match_id\": match.get(\"wyId\"),\n",
    "        \"date\": match.get(\"dateutc\"),\n",
    "        \"winner\": match.get(\"winner\"),\n",
    "        \"match_name\": match.get(\"label\"),\n",
    "        # Continue mapping team names for home and away teams\n",
    "        \"home_team\": team_name_dict.get(next((item for item in match.get(\"teamsData\").values() if item.get(\"side\") == 'home'), {}).get(\"teamId\", 0), \"Unknown\"),\n",
    "        \"away_team\": team_name_dict.get(next((item for item in match.get(\"teamsData\").values() if item.get(\"side\") == 'away'), {}).get(\"teamId\", 0), \"Unknown\"),\n",
    "        # Include IDs for home and away teams\n",
    "        \"home_team_id\": next((item for item in match.get(\"teamsData\").values() if item.get(\"side\") == 'home'), {}).get(\"teamId\", 0),\n",
    "        \"away_team_id\": next((item for item in match.get(\"teamsData\").values() if item.get(\"side\") == 'away'), {}).get(\"teamId\", 0)\n",
    "    } for match in json_data]\n",
    "    \n",
    "    df_match = pd.DataFrame(parsed_data)    \n",
    "    return df_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0945809b-3fbe-4d92-a268-c58089e4771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign which team caused event (home/away team)\n",
    "def adjust_team_caused_event(row):\n",
    "    if row['team_id'] == row['home_team_id']:  \n",
    "        return 'home_team'\n",
    "    elif row['team_id'] == row['away_team_id']:  \n",
    "        return 'away_team'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "# Map team names from the team id     \n",
    "def map_team_names(json_data_team):\n",
    "    team_name_dict = {item.get(\"wyId\", 0): item.get(\"name\", \"Draw\") for item in json_data_team}\n",
    "    return team_name_dict\n",
    "\n",
    "# Making match names consistent to merge with betting data\n",
    "def reformat_match_info(s):\n",
    "    pattern = re.compile(r'(.+?)\\s*-\\s*(.+?),\\s*\\d+\\s*-\\s*\\d+')\n",
    "    return pattern.sub(r'\\1 v \\2', s)\n",
    "\n",
    "# Map tag IDs to descriptions\n",
    "def load_tags_mapping(file_path):\n",
    "    tags_decode_df = pd.read_csv(file_path)\n",
    "    return tags_decode_df.set_index('Tag')['Label'].to_dict()\n",
    "\n",
    "def map_ids_to_descriptions(ids, tags_decode_dict):\n",
    "    return [tags_decode_dict.get(id) for id in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eacf03-183f-4e90-9ed9-02ddf905e562",
   "metadata": {},
   "source": [
    "#### Applying Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4843a24a-9afb-4a1b-a459-38429cb20f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh\\AppData\\Local\\Temp\\ipykernel_14340\\2049933243.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_events = df_events.groupby('match_id').apply(adjust_time_and_create_breaks).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "events_file_path = \"D:/ARU Modules/Final Project/dataset/events_England.json\" # Contains events info of the match\n",
    "matches_file_path = \"D:/ARU Modules/Final Project/dataset/matches_England.json\" # Info for date and time of match\n",
    "teams_file_path = \"D:/ARU Modules/Final Project/dataset/teams.json\" # list of team ID and team names\n",
    "tags_file_path = \"D:/ARU Modules/Final Project/dataset/tags2name.csv\" #to find tag ID info for events\n",
    "\n",
    "# Load JSON data\n",
    "events_json = load_json(events_file_path)\n",
    "matches_json = load_json(matches_file_path)\n",
    "teams_json = load_json(teams_file_path)\n",
    "\n",
    "# Create dict for team IDs and team names\n",
    "team_name_dict = map_team_names(teams_json)\n",
    "\n",
    "# Parse and process events data\n",
    "df_events = parse_events_data(events_json,team_name_dict)\n",
    "df_events = df_events.groupby('match_id').apply(adjust_time_and_create_breaks).reset_index(drop=True)\n",
    "\n",
    "# Mapping Match & Team names \n",
    "df_matches = parse_matches_data(matches_json, team_name_dict)\n",
    "\n",
    "# Load tags mapping and apply to events data\n",
    "tags_decode_dict = load_tags_mapping(tags_file_path)\n",
    "df_events['tags'] = df_events['tags'].apply(lambda ids: map_ids_to_descriptions(ids, tags_decode_dict))\n",
    "\n",
    "# Apply transformations to matches data\n",
    "df_matches['winner'] = df_matches['winner'].map(team_name_dict)\n",
    "df_matches['match_name'] = df_matches['match_name'].apply(reformat_match_info)\n",
    "\n",
    "# Merge events and matches data\n",
    "merged_df = pd.merge(df_events, df_matches, how='left', on='match_id')\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "# Apply the function to find which team caused the event to the merged dataframe\n",
    "merged_df['team_caused_event'] = merged_df.apply(adjust_team_caused_event, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c2d72-fa82-4e1c-8f58-54688637c3b0",
   "metadata": {},
   "source": [
    "### Fix for Handling Draw as Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db3e650-42d5-47d3-a067-d0dc0137f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Since the mapping teams json file doesnt have the id for the draw, it leaves a NaN value for the winner if the match was draw\n",
    "The below code does a hot fix and handles the dataframe for futher processing by assigning filling the NaN values in the winner column with Draw stirng\n",
    "and further generating the lables for the dataset that will be used later by the ML model\n",
    "'''\n",
    "# Fill NA values with \"Draw\"\n",
    "merged_df[\"winner\"] = merged_df[\"winner\"].fillna(\"Draw\")\n",
    "\n",
    "# Reset winner flags for all rows initially\n",
    "merged_df['home_winner'] = 0\n",
    "merged_df['away_winner'] = 0\n",
    "merged_df['draw_winner'] = 0\n",
    "\n",
    "# Group by 'match_id'\n",
    "grouped = merged_df.groupby('match_id')\n",
    "\n",
    "# Iterate over each group\n",
    "for match_id, group in grouped:\n",
    "    # Get the index of the first row in the group\n",
    "    first_index = group.index[0]\n",
    "    winner = group.loc[first_index, 'winner']\n",
    "    \n",
    "    # Determine the outcome based on the winner and assign flags accordingly\n",
    "    if winner == group.loc[first_index, 'home_team']:\n",
    "        merged_df.loc[group.index, 'home_winner'] = 1\n",
    "    elif winner == group.loc[first_index, 'away_team']:\n",
    "        merged_df.loc[group.index, 'away_winner'] = 1\n",
    "    elif winner == \"Draw\":\n",
    "        merged_df.loc[group.index, 'draw_winner'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f265ff2-eb8b-4cc3-9752-a3561d2a4a21",
   "metadata": {},
   "source": [
    "### Adding the publishTime to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb02248-8e3c-43e9-a0e1-9dc6233ae95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To align this events dataset to the betting dataset, we are using the date of the match and eventSec \n",
    "#To add the publishTime to the dataset, this will help us to align this events dataset to the betting dataset\n",
    "merged_df['publishTime'] = (merged_df['date'] + pd.to_timedelta(merged_df['event_sec'], unit='s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048eb136-decc-4c42-899d-d52c3f25b1a4",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f18c2dd-244f-40ba-a2df-f09368c029be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh\\AppData\\Local\\Temp\\ipykernel_14340\\4011116860.py:202: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  processed_df = merged_df.groupby('match_id').apply(process_match).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "class MatchMetrics:\n",
    "    def __init__(self):\n",
    "        # Metrics initialization\n",
    "        self.reset_metrics()\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.ht_attack_intensity = []\n",
    "        self.at_attack_intensity = []\n",
    "        self.ht_defense_intensity = []\n",
    "        self.at_defense_intensity = []\n",
    "        self.ht_total_possession_time = 0\n",
    "        self.at_total_possession_time = 0\n",
    "        self.ht_passes = {'accurate': 0, 'total': 0}\n",
    "        self.at_passes = {'accurate': 0, 'total': 0}\n",
    "        self.last_event_time = 0\n",
    "\n",
    "        # Dynamic metrics lists\n",
    "        self.ht_pos = []\n",
    "        self.at_pos = []\n",
    "        self.ht_pass_accuracy = []\n",
    "        self.at_pass_accuracy = []\n",
    "        \n",
    "        # Initialize lists for dynamic tracking of disciplinary actions\n",
    "        self.ht_red_cards = []\n",
    "        self.at_red_cards = []\n",
    "        self.ht_yellow_cards = []\n",
    "        self.at_yellow_cards = []\n",
    "        self.ht_other_fouls = []\n",
    "        self.at_other_fouls = []\n",
    "        self.last_event_time = 0\n",
    "        \n",
    "        # Initialize goal counts\n",
    "        self.ht_goals = []\n",
    "        self.at_goals = []\n",
    "        self.ht_goal_count = 0\n",
    "        self.at_goal_count = 0\n",
    "\n",
    "    def update_metrics(self, event, team_caused_event, sub_event, tags, event_sec):\n",
    "        # Calculate time since the last event for dynamic updates\n",
    "        time_since_last_event = event_sec - self.last_event_time\n",
    "        self.last_event_time = event_sec\n",
    "\n",
    "        # Update metrics based on event details\n",
    "        if event == \"Pass\":\n",
    "            self._update_passes(team_caused_event, tags)\n",
    "        self._update_attack_intensity(team_caused_event, sub_event, tags)\n",
    "        self._calculate_metrics(time_since_last_event, team_caused_event)\n",
    "        self._update_defense_intensity(team_caused_event, sub_event, tags)\n",
    "        self._update_disciplinary_actions(team_caused_event, sub_event, tags, event_sec)\n",
    "        self._update_goals(team_caused_event, tags, event_sec)\n",
    "        \n",
    "    def _update_goals(self, team_caused_event, tags, event_sec):\n",
    "        if 'Goal' in tags and 'accurate' in tags:\n",
    "            if team_caused_event == \"home_team\":\n",
    "                self.ht_goal_count += 1\n",
    "                # Append current goal count with the timestamp of the event\n",
    "                self.ht_goals.append((event_sec, self.ht_goal_count))\n",
    "            elif team_caused_event == \"away_team\":\n",
    "                self.at_goal_count += 1\n",
    "                # Append current goal count with the timestamp of the event\n",
    "                self.at_goals.append((event_sec, self.at_goal_count))\n",
    "                \n",
    "        if 'own_goal' in tags:\n",
    "            if team_caused_event == \"home_team\":\n",
    "                self.at_goal_count += 1\n",
    "                # Append current goal count with the timestamp of the event\n",
    "                self.at_goals.append((event_sec, self.at_goal_count))\n",
    "            elif team_caused_event == \"away_team\":\n",
    "                self.ht_goal_count += 1\n",
    "                # Append current goal count with the timestamp of the event\n",
    "                self.ht_goals.append((event_sec, self.ht_goal_count))\n",
    "                \n",
    "    def _update_disciplinary_actions(self, team_caused_event, sub_event, tags, event_sec):\n",
    "        # Increment counters based on the type of disciplinary action\n",
    "        action_increment = {\n",
    "            'red_cards': 'red_card' in tags or 'second_yellow_card' in tags,\n",
    "            'yellow_cards': 'yellow_card' in tags,\n",
    "            'other_fouls': sub_event in ['Foul', 'Violent Foul', 'Late card foul', 'Out of game foul', 'Penalty']\n",
    "        }\n",
    "\n",
    "        for action, condition in action_increment.items():\n",
    "            if condition:\n",
    "                if team_caused_event == \"home_team\":\n",
    "                    current_count = len(self.__dict__[f'ht_{action}']) + 1\n",
    "                    self.__dict__[f'ht_{action}'].append((event_sec, current_count))\n",
    "                elif team_caused_event == \"away_team\":\n",
    "                    current_count = len(self.__dict__[f'at_{action}']) + 1\n",
    "                    self.__dict__[f'at_{action}'].append((event_sec, current_count))\n",
    "\n",
    "\n",
    "    def _update_passes(self, team_caused_event, tags):\n",
    "        if team_caused_event == \"home_team\":\n",
    "            self.ht_passes['total'] += 1\n",
    "            if 'accurate' in tags:\n",
    "                self.ht_passes['accurate'] += 1\n",
    "        elif team_caused_event == \"away_team\":\n",
    "            self.at_passes['total'] += 1\n",
    "            if 'accurate' in tags:\n",
    "                self.at_passes['accurate'] += 1\n",
    "\n",
    "    def _update_attack_intensity(self, team_caused_event, sub_event, tags):\n",
    "        # Define attacking events and tags\n",
    "        attacking_events = ['Ground attacking duel', 'Shot', 'Cross', 'Corner', 'Free Kick']\n",
    "        attacking_tags = ['Goal', 'assist', 'keyPass', 'direct', 'free kick shot']\n",
    "\n",
    "        # Check if the current event qualifies as an attacking effort\n",
    "        is_attacking_event = sub_event in attacking_events and any(tag in attacking_tags for tag in tags)\n",
    "\n",
    "        # Update attack intensity based on the event\n",
    "        if team_caused_event == \"home_team\" and is_attacking_event:\n",
    "            self.ht_attack_intensity.append(1)  # Representing an attacking event\n",
    "        else:\n",
    "            self.ht_attack_intensity.append(0)  # No attacking event\n",
    "\n",
    "        if team_caused_event == \"away_team\" and is_attacking_event:\n",
    "            self.at_attack_intensity.append(1)\n",
    "        else:\n",
    "            self.at_attack_intensity.append(0)\n",
    "            \n",
    "    def _update_defense_intensity(self, team_caused_event, sub_event, tags):\n",
    "        # Define defensive events and tags\n",
    "        defensive_events = ['Ground defending duel', 'Air duel', 'Interception', 'Clearance']\n",
    "        defensive_tags = ['interception', 'clearance', 'won']  # Example tags\n",
    "\n",
    "        # Check if the current event qualifies as a defensive effort\n",
    "        is_defensive_event = sub_event in defensive_events and any(tag in defensive_tags for tag in tags)\n",
    "\n",
    "        # Update defense intensity based on the event\n",
    "        if team_caused_event == \"home_team\" and is_defensive_event:\n",
    "            self.ht_defense_intensity.append(1)  # Representing a defensive event\n",
    "        else:\n",
    "            self.ht_defense_intensity.append(0)  # No defensive event\n",
    "\n",
    "        if team_caused_event == \"away_team\" and is_defensive_event:\n",
    "            self.at_defense_intensity.append(1)\n",
    "        else:\n",
    "            self.at_defense_intensity.append(0)\n",
    "\n",
    "    def _calculate_metrics(self, time_since_last_event, team_caused_event):\n",
    "        # Update total possession time based on the event's team\n",
    "        if team_caused_event == \"home_team\":\n",
    "            self.ht_total_possession_time += time_since_last_event\n",
    "        elif team_caused_event == \"away_team\":\n",
    "            self.at_total_possession_time += time_since_last_event\n",
    "\n",
    "        # Dynamic possession and pass accuracy calculations\n",
    "        current_total_time = self.ht_total_possession_time + self.at_total_possession_time\n",
    "        ht_pos_pct = (self.ht_total_possession_time / current_total_time) * 100 if current_total_time > 0 else 50\n",
    "        at_pos_pct = (self.at_total_possession_time / current_total_time) * 100 if current_total_time > 0 else 50\n",
    "        ht_pass_acc = (self.ht_passes['accurate'] / self.ht_passes['total']) * 100 if self.ht_passes['total'] > 0 else 0\n",
    "        at_pass_acc = (self.at_passes['accurate'] / self.at_passes['total']) * 100 if self.at_passes['total'] > 0 else 0\n",
    "\n",
    "        # Append the current metrics to their respective lists\n",
    "        self.ht_pos.append(ht_pos_pct)\n",
    "        self.at_pos.append(at_pos_pct)\n",
    "        self.ht_pass_accuracy.append(ht_pass_acc)\n",
    "        self.at_pass_accuracy.append(at_pass_acc)\n",
    "\n",
    "    def append_metrics_to_df(self, match_df):\n",
    "        # Normalize attack intensity over the number of events\n",
    "        match_df['ht_attack_intensity'] = self._normalize_intensity(self.ht_attack_intensity)\n",
    "        match_df['at_attack_intensity'] = self._normalize_intensity(self.at_attack_intensity)\n",
    "        match_df['ht_defense_intensity'] = self._normalize_intensity(self.ht_defense_intensity)\n",
    "        match_df['at_defense_intensity'] = self._normalize_intensity(self.at_defense_intensity)\n",
    "        \n",
    "\n",
    "        # Append other dynamic metrics\n",
    "        match_df['ht_pos_pct'] = self.ht_pos\n",
    "        match_df['at_pos_pct'] = self.at_pos\n",
    "        match_df['ht_pass_accuracy'] = self.ht_pass_accuracy\n",
    "        match_df['at_pass_accuracy'] = self.at_pass_accuracy\n",
    "        \n",
    "        # Append dynamic goal counts\n",
    "        match_df['ht_goals'] = [len([t for t, _ in self.ht_goals if t <= event_sec]) for event_sec in match_df['event_sec']]\n",
    "        match_df['at_goals'] = [len([t for t, _ in self.at_goals if t <= event_sec]) for event_sec in match_df['event_sec']]\n",
    "\n",
    "    \n",
    "        #Append fouls during the match\n",
    "        for action in ['red_cards', 'yellow_cards', 'other_fouls']:\n",
    "            match_df[f'ht_{action}'] = [len([t for t, _ in self.__dict__[f'ht_{action}'] if t <= event_sec]) for event_sec in match_df['event_sec']]\n",
    "            match_df[f'at_{action}'] = [len([t for t, _ in self.__dict__[f'at_{action}'] if t <= event_sec]) for event_sec in match_df['event_sec']]\n",
    "            \n",
    "            \n",
    "        return match_df\n",
    "\n",
    "\n",
    "    def _normalize_intensity(self, intensity_list):\n",
    "        # Normalize attack intensity by converting to a percentage of total events\n",
    "        total_events = len(intensity_list)\n",
    "        normalized_intensity = [sum(intensity_list[:i+1])/total_events*100 for i in range(total_events)]\n",
    "        return normalized_intensity\n",
    "\n",
    "def process_match(match_df):\n",
    "    metrics_calculator = MatchMetrics()\n",
    "    \n",
    "    for index, row in match_df.iterrows():\n",
    "        metrics_calculator.update_metrics(row['event_name'], row['team_caused_event'], row['sub_event_name'], row['tags'], row['event_sec'])\n",
    "    \n",
    "    return metrics_calculator.append_metrics_to_df(match_df)\n",
    "\n",
    "# Apply the processing to each match\n",
    "processed_df = merged_df.groupby('match_id').apply(process_match).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b4506cca-52b2-4c29-bff1-8a476c0cfedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"processed_df/event_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f2aa7-fd16-42a8-a68b-168259b556a1",
   "metadata": {},
   "source": [
    "### Sorting Home/Away Team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7a7a4d6a-3d5b-4f51-bcde-52c28373e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since we have dont have home/away team info in the betting dataset, we will use this dataframe to extract the home team and away team \n",
    "we will use this to map the team names in the betting dataset. For this we will validate the matches with the match_id and the publishTime\n",
    "\"\"\"\n",
    "# Convert 'publishTime' to datetime if it's not already, and then extract the date part\n",
    "#processed_df['publishTime'] = pd.to_datetime(processed_df['publishTime']).dt.date\n",
    "\n",
    "# Drop duplicates keeping the first occurrence of each 'match_id'\n",
    "unique_matches_df = processed_df.drop_duplicates(subset=['match_id'], keep='first')\n",
    "\n",
    "# Keep only the desired columns\n",
    "unique_matches_df = unique_matches_df[['home_team', 'away_team', 'match_id', 'publishTime']]\n",
    "\n",
    "unique_matches_df.to_csv(\"processed_df/map_home_away_team.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
